{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generative StyleGAN 2 ADA"
      ],
      "metadata": {
        "id": "bCidZdRqLa9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First thing, mount the Google drive allowing for this pytorch code to read/write to the desired Google Drive."
      ],
      "metadata": {
        "id": "VS3FER8iLoHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP1f_AXYMPeA",
        "outputId": "8b3b54ac-4f61-410f-8aad-9a4d21dc74c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# StyleGAN 2 ADA Installation"
      ],
      "metadata": {
        "id": "zDFSsnF_T0ws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the next cell installs the StyleGAN 2 ADA repository. This can be installed now for later if the Google Drive isn't ready for mounting. "
      ],
      "metadata": {
        "id": "zn09e5BwT-LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/colab-sg2-ada-pytorch\"):\n",
        "    %cd \"/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n",
        "elif os.path.isdir(\"/content/drive/\"):\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !mkdir colab-sg2-ada-pytorch\n",
        "    %cd colab-sg2-ada-pytorch\n",
        "    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU -O /content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/pretrained/wikiart.pkl\n",
        "else:\n",
        "    !git clone https://github.com/dvschultz/stylegan2-ada-pytorch\n",
        "    %cd stylegan2-ada-pytorch\n",
        "    !mkdir downloads\n",
        "    !mkdir datasets\n",
        "    !mkdir pretrained\n",
        "    %cd pretrained\n",
        "    !gdown --id 1-5xZkD8ajXw1DdopTkH_rAoCsD72LhKU\n",
        "    %cd ../\n",
        "\n",
        "!pip install ninja opensimplex torch==1.7.1 torchvision==0.8.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "kZVQ4WGaTzs-",
        "outputId": "ad83c32e-d09e-4e62-ca13-508811122177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting opensimplex\n",
            "  Downloading opensimplex-0.4.3-py3-none-any.whl (19 kB)\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp38-cp38-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 4.0 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp38-cp38-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.7.1) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.7.1) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 391 kB/s \n",
            "\u001b[?25hInstalling collected packages: numpy, torch, torchvision, opensimplex, ninja\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0+cu116\n",
            "    Uninstalling torch-1.13.0+cu116:\n",
            "      Successfully uninstalled torch-1.13.0+cu116\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.14.0+cu116\n",
            "    Uninstalling torchvision-0.14.0+cu116:\n",
            "      Successfully uninstalled torchvision-0.14.0+cu116\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.7.1 which is incompatible.\n",
            "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.1 which is incompatible.\u001b[0m\n",
            "Successfully installed ninja-1.11.1 numpy-1.24.1 opensimplex-0.4.3 torch-1.7.1 torchvision-0.8.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the next cell will update the previously installed StyleGAN 2 repository "
      ],
      "metadata": {
        "id": "vBtRrWwMUwqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/My Drive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\"\n",
        "!git config --global user.name \"test\"\n",
        "!git config --global user.email \"test@test.com\"\n",
        "!git fetch origin\n",
        "!git pull\n",
        "!git stash\n",
        "!git checkout origin/main -- train.py generate.py legacy.py closed_form_factorization.py flesh_digression.py apply_factor.py README.md calc_metrics.py training/stylegan2_multi.py training/training_loop.py util/utilgan.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXWsEZrDU-Nk",
        "outputId": "910a74ee-ee02-431c-aa37-a72de19213dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch\n",
            "Already up to date.\n",
            "Saved working directory and index state WIP on main: 59e05bb added opensimplex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "F6Ca585dVD4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next few cells will install the zipped dataset into the correct folder within StyleGAN 2. First upload the zipped dataset folder into /content/drive. Once complete run the next cell which will unzip the folder."
      ],
      "metadata": {
        "id": "fOszjRMFVJ7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/garments-dataset.zip') as zip_ref:\n",
        "    zip_ref.extractall('/content/drive/MyDrive/garments-dataset')"
      ],
      "metadata": {
        "id": "Zap8R-yEWAKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify all the images within the unzipped dataset, run the next cell. It will check the format for every single image within the dataset. Providing promts one issues, 4 tensors = 4 channels which is not accepted. The images must be RGB and follow the same pixel size as descripted within the downloaded pretrained model, ranging from 512 x 512 and 1024 x 1024. "
      ],
      "metadata": {
        "id": "CD1b9LzUXyUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check size and colour format of images\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "IMAGE_PATH = '/content/drive/MyDrive/garments-dataset/garments-dataset'\n",
        "files = [f for f in listdir(IMAGE_PATH) if isfile(join(IMAGE_PATH, f))]\n",
        "\n",
        "base_size = None\n",
        "for file in tqdm(files):\n",
        "  file2 = os.path.join(IMAGE_PATH,file)\n",
        "  img = Image.open(file2)\n",
        "  sz = img.size\n",
        "  if base_size and sz!=base_size:\n",
        "    print(f\"Inconsistant size: {file2}\")\n",
        "  elif img.mode!='RGB':\n",
        "    print(f\"Inconsistant color format: {file2}\")\n",
        "  else:\n",
        "    base_size = sz"
      ],
      "metadata": {
        "id": "nTRRKbAoXwWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If there are no issues...\n",
        "\n",
        "Run the next cell, which will create the image destination folder within the StlyeGAN 2 Google Drive, which will use in a moment.  "
      ],
      "metadata": {
        "id": "TcQtnfyjWCKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/datasets/garments_square')"
      ],
      "metadata": {
        "id": "Jt8Np74CXGVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the dataset folder has been created within the StyleGAN 2. It allows for the next cell to transfer and process the images with the pytorch dataset tool from the zipped folder into the StyleGAN 2 dataset folder. "
      ],
      "metadata": {
        "id": "OTwqBnXBXK4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/dataset_tool.py --source /content/drive/MyDrive/garments-dataset/garments-dataset --dest /content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/datasets/garments_square"
      ],
      "metadata": {
        "id": "UKz32la1Xqz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After selecting the desired pre-trained model from the resources, upload the PKL file into google drive. The next cell will transfer the PKL file into the correct StyleGAN 2 folder. /pretrained"
      ],
      "metadata": {
        "id": "5G18X1iSZDH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv '/content/drive/MyDrive/pretrained_model/network-snapshot-026392.pkl' '/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/pretrained'"
      ],
      "metadata": {
        "id": "cewehm9DZqo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "dNBJc0e0ZzEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the pretrained PKL file and the images are in the correct folders within the StyleGAN 2. Training can take place using the uploaded PKL file as a base and then building ontop of it. "
      ],
      "metadata": {
        "id": "z7LsXXM-Z5bS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the paths to match for specific applications. When start new training start from aug_strength 0 and train count 0. Running the next cell prepares the folders. "
      ],
      "metadata": {
        "id": "cOXOJcDqawos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#required: definitely edit these!\n",
        "dataset_path = '/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/datasets/garments_square/00000'\n",
        "# resume_from = './pretrained/wikiart.pkl'\n",
        "resume_from = '/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/results/00006-00000-mirror-11gb-gpu-gamma50-bg-resumecustom/network-snapshot-000248.pkl'\n",
        "\n",
        "aug_strength = 1.160\n",
        "train_count = 248\n",
        "\n",
        "mirror_x = True\n",
        "#mirror_y = False\n",
        "\n",
        "#optional: you might not need to edit these\n",
        "gamma_value = 50.0\n",
        "augs = 'bg'\n",
        "config = '11gb-gpu'\n",
        "snapshot_count = 1"
      ],
      "metadata": {
        "id": "nxtV6VtKamUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the next line start the training with the parameters set above. \n"
      ],
      "metadata": {
        "id": "HeP6_4RsbISR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --gpus=1 --cfg=$config --metrics=None --outdir=./results --data=$dataset_path --snap=$snapshot_count --resume=$resume_from --augpipe=$augs --initstrength=$aug_strength --gamma=$gamma_value --mirror=$mirror_x --mirrory=False --nkimg=$train_count"
      ],
      "metadata": {
        "id": "G8CE_CgubQLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training session may cut, note down the aug_strength and train count. Adject the paramerts with the PKL file from the /results within StyleGAN 2 ADA.\n",
        "\n"
      ],
      "metadata": {
        "id": "jUiPe9SKbRIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "jCJdjWaScATy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell will generate images from the PKL file that's directed. Creating a single image for the PKL file. "
      ],
      "metadata": {
        "id": "CyscqX82cOvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=/content/out/images/ --trunc=0.8 --seeds=10 --network=''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPnRqK1zcd_U",
        "outputId": "f1cae1a8-2ac2-4ea7-9440-a5a73b0f68d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generate.py:59: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  elif(len(seeds) is not 3):\n",
            "Traceback (most recent call last):\n",
            "  File \"generate.py\", line 25, in <module>\n",
            "    from opensimplex import OpenSimplex\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opensimplex/__init__.py\", line 4, in <module>\n",
            "    from .api import *\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opensimplex/api.py\", line 2, in <module>\n",
            "    from .internals import _init, _noise2, _noise3, _noise4, _noise2a, _noise3a, _noise4a\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opensimplex/internals.py\", line 9, in <module>\n",
            "    from numba import njit, prange\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/numba/__init__.py\", line 42, in <module>\n",
            "    from numba.np.ufunc import (vectorize, guvectorize, threading_layer,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/numba/np/ufunc/__init__.py\", line 3, in <module>\n",
            "    from numba.np.ufunc.decorators import Vectorize, GUVectorize, vectorize, guvectorize\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/numba/np/ufunc/decorators.py\", line 3, in <module>\n",
            "    from numba.np.ufunc import _internal\n",
            "SystemError: initialization of _internal failed without raising an exception\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom pixel sized image outputs. "
      ],
      "metadata": {
        "id": "ZL5L1tYodZV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=/content/out/images/ --trunc=0.7 --size=1820-1024 --scale-type=symm --seeds=0-499 --network='/content/drive/MyDrive/colab-sg2-ada-pytorch/stylegan2-ada-pytorch/results/00007-00000-mirror-11gb-gpu-gamma50-bg-resumecustom/network-snapshot-000308.pkl'"
      ],
      "metadata": {
        "id": "lvuG7hAgd459"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realist images"
      ],
      "metadata": {
        "id": "eXtEQbVVd4Z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --process=\"truncation\" --outdir=/content/out/trunc-trav-3/ --start=-0.8 --stop=2.8 --increment=0.02 --seeds=470 --network='./pretrained/network-snapshot-027750.pkl'"
      ],
      "metadata": {
        "id": "VrS4a380eHlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Interpolation"
      ],
      "metadata": {
        "id": "3nXnnl1FeazR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=/content/out/video1-w-0.5/ --space=\"z\" --trunc=0.5 --process=\"interpolation\" --seeds=463,470 --network='./pretrained/network-snapshot-027750.pkl'"
      ],
      "metadata": {
        "id": "4MmaSui9ec7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slerp Interpolation"
      ],
      "metadata": {
        "id": "nVX9rBDhexhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=out/slerp-z/ --space=\"z\" --trunc=1 --process=\"interpolation\" --interpolation=\"slerp\" --seeds=85,265,297,849 --network='./pretrained/network-snapshot-027750.pkl' --frames=24"
      ],
      "metadata": {
        "id": "AF-65xTWezxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noise Loop"
      ],
      "metadata": {
        "id": "EAXy0j7pe47u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=out/video-noiseloop-0.9d/ --trunc=0.8 --process=\"interpolation\" --interpolation=\"noiseloop\" --diameter=0.9 --random_seed=100 --network='./pretrained/network-snapshot-027750.pkl'"
      ],
      "metadata": {
        "id": "W6yCfCQre4YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Circular Loop"
      ],
      "metadata": {
        "id": "TQdW93JXfEYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py --outdir=out/video-circularloop/ --trunc=1 --process=\"interpolation\" --interpolation=\"circularloop\" --diameter=800.00 --frames=720 --random_seed=90 --network='./pretrained/network-snapshot-027750.pkl'"
      ],
      "metadata": {
        "id": "UFiWPCzxfFAd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}